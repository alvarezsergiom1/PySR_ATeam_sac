{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS4E1PagbDgL"
   },
   "source": [
    "### Example of Symbolic Regression to estimate LAI from spectral and structural data in vineyards\n",
    "\n",
    "Data generated by Sergio Alvarez, GRAPEX project.\n",
    "\n",
    "Utah State University, 2025.\n",
    "\n",
    "File '03_df_bands_structure_VI_LAI_NDVIc.csv' contains as potential predictors\n",
    "- Reflectance values from canopy\n",
    "- Vegetation indices for canopy\n",
    "- Geometric information (H, widht, etc) per vine\n",
    "- two predictants (afc, LAI) in the last colunms.\n",
    "\n",
    "In this file, we will try to use all available predictants for model LAI, we have already generated VIs from a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ1r1bbb0yBv"
   },
   "source": [
    "### Instructions\n",
    "- if not, create a anaconda environment, e.g. \n",
    "```bash\n",
    "conda create -n pysr\n",
    "```\n",
    "- once completed the step above in the pysr environment install these modules:\n",
    "```bash\n",
    "conda install pysr\n",
    "conda install matplotlib\n",
    "pip install skillmetrics\n",
    "```\n",
    "- final step, in the activated environment and pass this command:\n",
    "```bash\n",
    "- python -c \"import pysr\"\n",
    "```\n",
    "- last commands will install julia libraries, necessary to run the notebook.\n",
    "\n",
    "- To visualize the results install Jinja2\n",
    "```bash\n",
    "conda install jinja2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PySR \n",
    "\n",
    "Julia and Julia dependencies are installed at first import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeCPKd9wldEK"
   },
   "source": [
    "Now, let's import everything else as well as the PySRRegressor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFpyRxmhFqeH"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sympy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skill_metrics as sm\n",
    "import mpl_scatter_density # adds projection='scatter_density'\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsRMQ7grbDga"
   },
   "source": [
    "### Set up PySR run:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myTEwdiUFiGL"
   },
   "source": [
    "using Sergio's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('03_df_bands_structure_VI_LAI_NDVIc.csv')\n",
    "# print(df.head())\n",
    "X = df.iloc[:,1:-3]\n",
    "y = df.iloc[:,-2]\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key pySR parameters to be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niterations = 100  # for short runs, set this to a 100, for longer runs, set this to 10 million\n",
    "timeout_in_seconds = 3600*2  # this line will make the code stop after 2 hours, change it as desired.\n",
    "elementwise_loss = \"L2DistLoss()\"  #  (mean square) can be changed to \"L1DistLoss()\" for mean absolute error, see link at the end for more options\n",
    "binary_operators = [\"+\", \"*\",\"-\",\"/\",\"^\"] # these are the default binary operators (use these for basic equations)\n",
    "# binary_operators = [\"+\", \"*\",\"-\",\"/\",\"^\",\"ND(x,y) = ((x-y)/(x+y))\", \"SR(x,y)=x/y\"]  # activate this line to use simple ratio and normalized diference functions (comment the repvious line)\n",
    "# unary_operators = [\"sqrt\", \"exp\", \"log\", \"inv(x)=1/x\"]  # other basic operators can be added here\n",
    "extra_sympy_mappings = {\"inv\": lambda x: 1 / x,\"ND\": lambda x, y: ((x- y)/(x+y)),\"SR\": lambda x, y: x/y}  # here the format of the sought expressions are defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cturCkaVjzLs"
   },
   "source": [
    "The default parameters will help speed up code and ensure repeteability of run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nDAAnisdhTc"
   },
   "outputs": [],
   "source": [
    "default_pysr_params = dict(\n",
    "    model_selection=\"best\", #\"score\", \"best\", see documentation for more options\n",
    "    random_state=0, # seed number to ensure reproducible results across different runs\n",
    "    deterministic=True, #   to ensure reproducible results across different runs\n",
    "    parallelism=\"serial\", # to ensure reproducible results across different runs\n",
    "    maxsize=50, # maximum complexity of the equations, increase to 100 for more complex equations, reduce to 20 for less complex equations   \n",
    "    select_k_features=10, # to automatically select few predictors (using random forest) from set of predictors, activate/deactive as you wish\n",
    "    # denoise=True, # to remove scattering on y, activate/deactivate as you wish\n",
    "    verbosity =0,   # 0 for no output, 1 for some output\n",
    "    elementwise_loss= \"L2DistLoss()\",  #  (mean square) can be changed to \"L1DistLoss()\" for mean absolute error, see link at the end for more options\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p4PSrO-NK1Wa",
    "outputId": "55910ab3-895d-400b-e9ce-c75aef639c68"
   },
   "outputs": [],
   "source": [
    "# Learn equations\n",
    "model = PySRRegressor(\n",
    "    niterations=niterations,  # for short runs, set this to a 100, for longer runs, set this to 10 million\n",
    "    timeout_in_seconds=timeout_in_seconds,  # this line will make the code stop after 2 hours\n",
    "    binary_operators=binary_operators, # activate this line to use simple ratio and normalized diference functions (comment the repvious line)\n",
    "    # unary_operators=unary_operators, # other basic operators can be added here\n",
    "    extra_sympy_mappings=extra_sympy_mappings, # here the format of the sought expressions are defined\n",
    "    turbo=True, # set to True to speed up the code \n",
    "    **default_pysr_params,\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bsAECbdkQsQ"
   },
   "source": [
    "We can print the model pareto curve, which will showcase the trend of discovered solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score=model.get_best().score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "4HR8gknlZz4W",
    "outputId": "496283bd-a743-4cc6-a2f9-9619ba91d870"
   },
   "outputs": [],
   "source": [
    "# best scoring equation (not the one with the lowest loss nor the one with the lowest complexity, but the one that optimally balances the two)\n",
    "scores = model.equations_.score\n",
    "# get the index of the first max\n",
    "# max_index = scores.idxmax(axis=0)\n",
    "max_index = scores == best_score\n",
    "max_index\n",
    "\n",
    "\n",
    "pareto =model.equations_.iloc[:, [0, 1]] # Print the equations found\n",
    "# pareto\n",
    "plt.plot(pareto.complexity,pareto.loss,'-o')\n",
    "plt.plot(pareto.complexity[max_index],pareto.loss[max_index],'ro',markersize=12)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Complexity\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "\n",
    "\n",
    "\n",
    "ii=0\n",
    "# zip joins x and y coordinates in pairs\n",
    "for p,q, in zip(pareto.complexity,pareto.loss):\n",
    "\n",
    "    label = \"{:.0f}\".format(ii)\n",
    "\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (p,q), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    ii=ii+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME3ddPxXkWQg"
   },
   "source": [
    "We can also view the SymPy format of the equation of our interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "IQKOohdpztS7",
    "outputId": "0e7d058a-cce1-45ae-db94-6625f7e53a06"
   },
   "outputs": [],
   "source": [
    "unique_max_index = max_index[max_index].index.tolist()\n",
    "model.sympy(unique_max_index[0])  # get the selected equation in sympy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect `model.equations_` structure\n",
    "print('model.equations_.columns ->', model.equations_.columns.tolist())\n",
    "# show the top rows for quick inspection\n",
    "try:\n",
    "    display(model.equations_.head())\n",
    "except Exception:\n",
    "    print(model.equations_.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHIIPlmClltn"
   },
   "source": [
    "We can also view the form of any other expression in the list, using the index of it in `model.equations_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39
    },
    "id": "GRcxq-TTlpRX",
    "outputId": "50bda367-1ed1-4860-8fcf-c940f2e4d935"
   },
   "outputs": [],
   "source": [
    "found_equations =model.equations_.iloc[:, [1,2]]  # print all the equations found\n",
    "# pd.set_option('display.max_colwidth',200)  \n",
    "# display(found_equations)\n",
    "\n",
    "# Apply a color ramp to the 'Score' column\n",
    "styled_df = found_equations.style.background_gradient(\n",
    "    subset=['loss'],  # Column to apply gradient\n",
    "    cmap='jet'      # Color map matplotlib colormap name\n",
    ")\n",
    "\n",
    "# Display in Jupyter Notebook\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMugcGX4tbqj"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the first solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Viridis-like\" colormap with white background\n",
    "white_viridis = LinearSegmentedColormap.from_list('white_viridis', [\n",
    "    (0, '#ffffff'),\n",
    "    (1e-20, \"#0004FF\"),\n",
    "    (0.2, \"#0818F6\"),\n",
    "    (0.4, \"#009d00\"),\n",
    "    (0.6, \"#009d0a\"),\n",
    "    (0.8, \"#fcfc01\"),\n",
    "    (1, \"#f2ff00\"),\n",
    "], N=256)\n",
    "\n",
    "num_eq = len(model.equations_)\n",
    "\n",
    "fig_rows = int(np.ceil(num_eq / 4))\n",
    "fig_cols = 4\n",
    "\n",
    "fig, axes = plt.subplots(fig_rows, fig_cols, figsize=(3*fig_cols, 3*fig_rows),sharey=True, sharex=True,subplot_kw=dict(projection=\"scatter_density\"))\n",
    "\n",
    "it = np.linspace(0,num_eq-1,num_eq, dtype=int)  # Ensure indices are integers\n",
    "\n",
    "# Iterate over the subplots and data\n",
    "for ax, i in zip(axes.flatten(), it):  # Flatten axes for proper iteration\n",
    "    ypredict_simpler = model.predict(X, index=i)  # Use integer index\n",
    "    # ypredict_simpler = pd.Series(np.asarray(ypredict_simpler).ravel(), index=y.index)\n",
    "\n",
    "    density=ax.scatter_density(ypredict_simpler, y, cmap=white_viridis)\n",
    "\n",
    "    # ax.plot(ypredict_simpler, y,'.')\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"Modeled\")\n",
    "    ax.set_ylabel(\"Measured\")\n",
    "    ax.plot( [0,5], [0,5], linestyle='--', color='k', linewidth=0.5 )\n",
    "    fig.colorbar(density, label='Number points', ax=ax)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(0, 5)\n",
    "    ax.set_ylim(0, 5)\n",
    "    mse = mean_squared_error(ypredict_simpler, y)\n",
    "    r2 = r2_score(y, ypredict_simpler)\n",
    "    ax.set_title('PySR Eq ' + str(i) + f\"\\nMSE: {mse:.1f}, R2: {r2:.2f}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(fig_rows, fig_cols, figsize=(3*fig_cols, 3*fig_rows),sharey=True, sharex=True)\n",
    "\n",
    "# Define bin interval and create bin edges\n",
    "bin_interval = 0.25  # Adjust this value to change bin width\n",
    "bins = np.arange(-2, 2 + bin_interval, bin_interval)\n",
    "\n",
    "# Iterate over the subplots and data\n",
    "for ax, i in zip(axes.flatten(), it):  # Flatten axes for proper iteration\n",
    "    ypredict_simpler = model.predict(X, index=i)  # Use integer index\n",
    "    ax.hist(ypredict_simpler- y, bins=bins, density=True, rwidth=0.8)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"Eq residual (var units)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    # ax.plot( [0,70], [0,70], linestyle='--', color='k' )\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    N = len(y)\n",
    "    mean = np.mean(ypredict_simpler - y)\n",
    "    ddof = 1  # Use sample standard deviation\n",
    "    d2 = abs(ypredict_simpler- y - mean)**2  # abs is for complex `a`\n",
    "    var = d2.sum() / (N - ddof)  # note use of `ddof`\n",
    "    std = var**0.5\n",
    "    r2 = r2_score(y, ypredict_simpler)\n",
    "    ax.set_title('PySR Eq ' + str(i) + f\"\\nstd: {std:.1f}, R2: {r2:.2f}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Taylor diagram with labeled data points and modified axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# number of equations found\n",
    "n_e= len(found_equations)\n",
    "\n",
    "it2 = np.linspace(0,n_e-1,n_e, dtype=int)  # Ensure indices are integers\n",
    "\n",
    "# Prepare data for Taylor diagram\n",
    "data = {}\n",
    "# data=pd.DataFrame(data)\n",
    "\n",
    "sdev = np.array([])\n",
    "crmsd = np.array([])\n",
    "ccoef = np.array([])\n",
    "\n",
    "data['ref'] = y.values  # Store reference data in data dictionary\n",
    "taylor_stats = sm.taylor_statistics(data['ref'],data['ref'])\n",
    "sdev = np.append(sdev,[taylor_stats['sdev'][0]])\n",
    "crmsd = np.append(crmsd,[taylor_stats['crmsd'][0]])\n",
    "ccoef = np.append(ccoef,[taylor_stats['ccoef'][0]])\n",
    "\n",
    "for i in it2:\n",
    "    ypredict_simpler = model.predict(X, index=i)  # Use integer index\n",
    "    data['pred'+str(i+1)] = ypredict_simpler  \n",
    "    taylor_stats = sm.taylor_statistics(data['pred'+str(i+1)],data['ref'])\n",
    "    sdev = np.append(sdev,[taylor_stats['sdev'][1]])\n",
    "    crmsd = np.append(crmsd,[taylor_stats['crmsd'][1]])\n",
    "    ccoef = np.append(ccoef,[taylor_stats['ccoef'][1]])\n",
    "    \n",
    "data = pd.DataFrame(data)\n",
    "data\n",
    "\n",
    "# Specify labels for points in a cell array (M1 for model prediction 1,\n",
    "# etc.). Note that a label needs to be specified for the reference even\n",
    "# though it is not used.\n",
    "label = ['Reference'] + ['Eq ' + str(i) for i in it2]    \n",
    "\n",
    "# Produce the Taylor diagram\n",
    "\n",
    "#     Label the points and change the axis options for SDEV, CRMSD, and CCOEF.\n",
    "intervalsCOR = np.concatenate((np.arange(0,1.0,0.2), \n",
    "                                   [0.9, 0.95, 0.99, 1]))\n",
    "sm.taylor_diagram(sdev,crmsd,ccoef, markerLabel = label,\n",
    "                      markerLabelColor = 'b', \n",
    "                      tickRMS= np.arange(0,2,0.5),\n",
    "                      tickRMSangle = 110.0, \n",
    "                      colRMS = 'm', styleRMS = ':', widthRMS = 2.0,\n",
    "                      tickSTD = np.arange(0,2,0.2), axismax = 2.0, \n",
    "                      colSTD = 'b', styleSTD = '-.', widthSTD = 1.0,\n",
    "                      colCOR = 'k', styleCOR = '--', widthCOR = 1.0)\n",
    "# plt.title('Taylor Diagram of Drone Thermal Camera Correction Models', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the three plots it is evident that Equations before #8 are not necesarily robust. Still Equation 3 is simple and the error histogram is narrow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "eq_indices = list(model.equations_.index)        # indices of discovered equations\n",
    "scores = {idx: [] for idx in eq_indices}\n",
    "residuals = {idx: [] for idx in eq_indices}  # collect residuals across folds for each equation\n",
    "\n",
    "# Use explicit dataset target to avoid accidental shadowing of `y`\n",
    "y_target = df.iloc[:, -2]\n",
    "\n",
    "for _, test_idx in kf.split(X):\n",
    "    X_test = X.iloc[test_idx]\n",
    "    # handle y_target as pandas Series or numpy array\n",
    "    if hasattr(y_target, \"iloc\"):\n",
    "        y_test = y_target.iloc[test_idx]\n",
    "    else:\n",
    "        y_test = np.asarray(y_target)[test_idx]\n",
    "\n",
    "    for idx in eq_indices:\n",
    "        ypred = model.predict(X_test, index=idx)\n",
    "        # ensure numpy arrays and flatten\n",
    "        y_test_arr = np.asarray(y_test).ravel()\n",
    "        ypred_arr = np.asarray(ypred).ravel()\n",
    "        # RMSE per fold (kept for backward compatibility)\n",
    "        scores[idx].append(np.sqrt(mean_squared_error(y_test_arr, ypred_arr)))\n",
    "        # collect residuals for final std calculation\n",
    "        residuals[idx].extend((y_test_arr - ypred_arr).tolist())\n",
    "\n",
    "# summarize\n",
    "rows = []\n",
    "for idx in eq_indices:\n",
    "    # compute residual std across all test predictions from CV folds\n",
    "    try:\n",
    "        resid_std = np.std(np.asarray(residuals[idx]), ddof=1)\n",
    "    except Exception:\n",
    "        resid_std = np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"index\": idx,\n",
    "        \"rmse_mean\": np.mean(scores[idx]),\n",
    "        \"rmse_std\": np.std(scores[idx], ddof=1),\n",
    "        \"resid_std\": resid_std,\n",
    "        \"complexity\": model.equations_.loc[idx, \"complexity\"],\n",
    "        \"equation\": model.equations_.loc[idx, \"equation\"],\n",
    "    })\n",
    "\n",
    "df_cv = pd.DataFrame(rows).sort_values(\"rmse_mean\")\n",
    "\n",
    "# show top 10 by mean RMSE\n",
    "# display(df_cv.head(10))\n",
    "\n",
    "# --- Plot: rmse_mean vs. complexity (colored by complexity) -----------\n",
    "# sort for plotting by numeric `complexity` so x-axis shows complexity order\n",
    "plot_df = df_cv.sort_values(\"complexity\").reset_index(drop=True)\n",
    "\n",
    "x = plot_df[\"complexity\"].values\n",
    "labels = plot_df[\"index\"].astype(str)\n",
    "y_vals = plot_df[\"rmse_mean\"].values\n",
    "yerr = plot_df[\"rmse_std\"].fillna(0).values\n",
    "comp = plot_df[\"complexity\"].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# draw vertical error bars first (no markers)\n",
    "ax.errorbar(x, y_vals, yerr=yerr, fmt='none', ecolor='black', alpha=0.7, capsize=3)\n",
    "# scatter points colored by complexity\n",
    "sc = ax.scatter(x, y_vals, c=comp, cmap='jet', s=80, edgecolor='k', linewidth=0.4, zorder=3)\n",
    "# add colorbar for complexity\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label('Complexity')\n",
    "\n",
    "# show equation index as tick labels at each complexity position\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_xlabel('Complexity')\n",
    "ax.set_ylabel('RMSE (mean)')\n",
    "ax.set_title('Cross-validated RMSE per discovered equation — x axis = complexity')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# draw small horizontal ticks at each model's 1·std value\n",
    "# choose width as a small fraction of x span so ticks remain compact\n",
    "if len(x) > 1:\n",
    "    x_span = np.max(x) - np.min(x)\n",
    "    width = max(x_span * 0.02, 0.1)\n",
    "else:\n",
    "    width = 0.1\n",
    "# use per-model residual std values if present, otherwise fall back to rmse_std\n",
    "resid_vals = plot_df.get(\"resid_std\", plot_df.get(\"rmse_std\")).fillna(0).values\n",
    "ax.hlines(y=resid_vals, xmin=x - width, xmax=x + width, colors='red', alpha=0.8, linewidth=1.25, zorder=2)\n",
    "\n",
    "# highlight best (lowest mean RMSE)\n",
    "best_pos = np.nanargmin(y_vals)\n",
    "best_x = x[best_pos]\n",
    "ax.scatter(best_x, y_vals[best_pos], facecolors='none', edgecolors='red', s=220, linewidth=1.6, zorder=5)\n",
    "ax.annotate(f\"best: {plot_df.loc[best_pos, 'index']}\\nRMSE={y_vals[best_pos]:.3f}\",\n",
    "            xy=(best_x, y_vals[best_pos]), xytext=(0, 8), textcoords='offset points',\n",
    "            ha='center', fontsize=9, bbox=dict(boxstyle='round', fc='w'))\n",
    "\n",
    "# label what the horizontal ticks represent\n",
    "ax.text(0.99, 0.95, 'Horizontal ticks = per-model 1·std', transform=ax.transAxes,\n",
    "        ha='right', va='top', fontsize=9, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QsHVjAVbDhk"
   },
   "source": [
    "# Other PySR Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5dO61g1bDhk"
   },
   "source": [
    "The full list of PySR parameters can be found here: https://ai.damtp.cam.ac.uk/pysr/api"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
